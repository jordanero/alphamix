{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48048b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import os\n",
    "import plotly.express as px\n",
    "from scipy.optimize import differential_evolution\n",
    "import sys\n",
    "sys.path.append('/n/groups/price/jordan/h2xancestry/scripts')\n",
    "import ldsc_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc433b5",
   "metadata": {},
   "source": [
    "# common domain sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f375863",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_df_list = []\n",
    "for w in [0, .05, .25, .5, .75, .95, 1]:\n",
    "    d = f'/n/groups/price/jordan/h2xancestry/data/simulations/alpha_mix_2/w_{w}_alpha_.38_h2_.5_thresholded_.005'\n",
    "    files = os.listdir(d)\n",
    "    grouped_trait_files = [f for f in files if f.endswith('common_domain.alpha_mix.skip_jackknife.txt') and f.startswith('seeds_')]\n",
    "    for f in grouped_trait_files:\n",
    "        df = pd.read_csv(\n",
    "            f'{d}/{f}', \n",
    "            sep = '\\t'\n",
    "        ).assign(\n",
    "            true_w = w,\n",
    "            seed_start = f.split('_')[1],\n",
    "            seed_end = f.split('_')[2].split('.')[0]\n",
    "        ).assign(inference = 'Baseline-LD (v2.2) + 2-D MAF bins')\n",
    "        w_df_list.append(df)\n",
    "w_df = pd.concat(w_df_list)\n",
    "w_df.groupby('true_w').apply(lambda df: pd.DataFrame({\n",
    "    'w_mean' : [df.w.mean()],\n",
    "    'w_std' : df.w.std(),\n",
    "    'n' : df.shape[0]\n",
    "}))\n",
    "px.box(\n",
    "    w_df,\n",
    "    x = 'true_w',\n",
    "    y = 'alpha',\n",
    ")\n",
    "#w_df.to_csv('/n/groups/price/jordan/h2xancestry/data/simulations/alpha_mix_2/simulation_summaries/alpha_.38_h2_.5_ukbb_common_domain.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5a5504",
   "metadata": {},
   "source": [
    "# European MAF misspecification sims "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2895596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_df_list = []\n",
    "for w in [0, .05, .25, .5, .75, .95, 1]:\n",
    "    files = os.listdir(f'/n/groups/price/jordan/h2xancestry/data/simulations/alpha_mix_2/w_{w}_alpha_.38_h2_.5_ukbb_british_maf')\n",
    "    grouped_trait_files = [f for f in files if f.endswith('.alpha_mix.skip_jackknife.txt') and f.startswith('seeds_')]\n",
    "    for f in grouped_trait_files:\n",
    "        df = pd.read_csv(\n",
    "            f'/n/groups/price/jordan/h2xancestry/data/simulations/alpha_mix_2/w_{w}_alpha_.38_h2_.5_ukbb_british_maf/{f}', \n",
    "            sep = '\\t'\n",
    "        ).assign(\n",
    "            true_w = w,\n",
    "            seed_start = f.split('_')[1],\n",
    "            seed_end = f.split('_')[2].split('.')[0]\n",
    "        ).assign(inference = 'Baseline-LD (v2.2) + 2-D MAF bins')\n",
    "        w_df_list.append(df)\n",
    "w_df = pd.concat(w_df_list)\n",
    "w_df.to_csv('/n/groups/price/jordan/h2xancestry/data/simulations/alpha_mix_2/simulation_summaries/alpha_.38_h2_.5_ukbb_british_maf.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e99f54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(\n",
    "    w_df,\n",
    "    x = 'true_w',\n",
    "    y = 'w',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40837cb4",
   "metadata": {},
   "source": [
    "# single trait estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a44444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_df_list = []\n",
    "for w in [0, .05, .25, .5, .75, .95, 1]:\n",
    "    files = os.listdir(f'/n/groups/price/jordan/h2xancestry/data/simulations/alpha_mix_2/w_{w}_alpha_.38_h2_.5_thresholded_.005')\n",
    "    grouped_trait_files = [f for f in files if f.endswith('.alpha_mix.skip_jackknife.txt') and f.startswith('seed_')]\n",
    "    for f in grouped_trait_files:\n",
    "        df = pd.read_csv(\n",
    "            f'/n/groups/price/jordan/h2xancestry/data/simulations/alpha_mix_2/w_{w}_alpha_.38_h2_.5_thresholded_.005/{f}', \n",
    "            sep = '\\t'\n",
    "        ).assign(\n",
    "            true_w = w,\n",
    "            seed_start = f.split('_')[1],\n",
    "            seed_end = f.split('_')[2].split('.')[0]\n",
    "        ).assign(inference = 'Baseline-LD (v2.2) + 2-D MAF bins')\n",
    "        w_df_list.append(df)\n",
    "w_df = pd.concat(w_df_list)\n",
    "w_df.to_csv('/n/groups/price/jordan/h2xancestry/data/simulations/alpha_mix_2/simulation_summaries/alpha_.38_h2_.5_thresholded_.005_indiv.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dda864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(\n",
    "    w_df,\n",
    "    x = 'true_w',\n",
    "    y = 'w',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1941463",
   "metadata": {},
   "source": [
    "# N causal = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4554ae60",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_df_list = []\n",
    "for w in [0, .05, .25, .5, .75, .95, 1]:\n",
    "    files = os.listdir(f'/n/groups/price/jordan/h2xancestry/data/simulations/alpha_mix_2/w_{w}_alpha_.38_h2_.5_n_causal_20000')\n",
    "    grouped_trait_files = [f for f in files if f.endswith('.alpha_mix.skip_jackknife.txt') and f.startswith('seeds')]\n",
    "    for f in grouped_trait_files:\n",
    "        df = pd.read_csv(\n",
    "            f'/n/groups/price/jordan/h2xancestry/data/simulations/alpha_mix_2/w_{w}_alpha_.38_h2_.5_n_causal_20000/{f}', \n",
    "            sep = '\\t'\n",
    "        ).assign(\n",
    "            true_w = w,\n",
    "            seed_start = f.split('_')[1],\n",
    "            seed_end = f.split('_')[2].split('.')[0]\n",
    "        ).assign(inference = 'Baseline-LD (v2.2) + 2-D MAF bins')\n",
    "        w_df_list.append(df)\n",
    "w_df = pd.concat(w_df_list)\n",
    "w_df.to_csv('/n/groups/price/jordan/h2xancestry/data/simulations/alpha_mix_2/simulation_summaries/alpha_.38_h2_.5_n_causal_20000.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ca520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(\n",
    "    w_df,\n",
    "    x = 'true_w',\n",
    "    y = 'w',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93a8ab7",
   "metadata": {},
   "source": [
    "# N causal = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a614a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_df_list = []\n",
    "for w in [0, .05, .25, .5, .75, .95, 1]:\n",
    "    files = os.listdir(f'/n/groups/price/jordan/h2xancestry/data/simulations/alpha_mix_2/w_{w}_alpha_.38_h2_.5_n_causal_5000')\n",
    "    grouped_trait_files = [f for f in files if f.endswith('.alpha_mix.skip_jackknife.txt') and f.startswith('seeds')]\n",
    "    for f in grouped_trait_files:\n",
    "        df = pd.read_csv(\n",
    "            f'/n/groups/price/jordan/h2xancestry/data/simulations/alpha_mix_2/w_{w}_alpha_.38_h2_.5_n_causal_5000/{f}', \n",
    "            sep = '\\t'\n",
    "        ).assign(\n",
    "            true_w = w,\n",
    "            seed_start = f.split('_')[1],\n",
    "            seed_end = f.split('_')[2].split('.')[0]\n",
    "        ).assign(inference = 'Baseline-LD (v2.2) + 2-D MAF bins')\n",
    "        w_df_list.append(df)\n",
    "w_df = pd.concat(w_df_list)\n",
    "w_df.to_csv('/n/groups/price/jordan/h2xancestry/data/simulations/alpha_mix_2/simulation_summaries/alpha_.38_h2_.5_n_causal_5000.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e1e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(\n",
    "    w_df,\n",
    "    x = 'true_w',\n",
    "    y = 'w',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a275474d",
   "metadata": {},
   "source": [
    "# T = .05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251deab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_df_list = []\n",
    "for w in [0, .05, .25, .5, .75, .95, 1]:\n",
    "    files = os.listdir(f'/n/groups/price/jordan/h2xancestry/data/simulations/alpha_mix_2/w_{w}_alpha_.38_h2_.5_thresholded_.05')\n",
    "    grouped_trait_files = [f for f in files if f.endswith('.alpha_mix.skip_jackknife.txt') and f.startswith('seeds')]\n",
    "    for f in grouped_trait_files:\n",
    "        df = pd.read_csv(\n",
    "            f'/n/groups/price/jordan/h2xancestry/data/simulations/alpha_mix_2/w_{w}_alpha_.38_h2_.5_thresholded_.05/{f}', \n",
    "            sep = '\\t'\n",
    "        ).assign(\n",
    "            true_w = w,\n",
    "            seed_start = f.split('_')[1],\n",
    "            seed_end = f.split('_')[2].split('.')[0]\n",
    "        ).assign(inference = 'Baseline-LD (v2.2) + 2-D MAF bins')\n",
    "        w_df_list.append(df)\n",
    "w_df = pd.concat(w_df_list)\n",
    "w_df.to_csv('/n/groups/price/jordan/h2xancestry/data/simulations/alpha_mix_2/simulation_summaries/alpha_.38_h2_.5_thresholded_.05.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f14aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(\n",
    "    w_df,\n",
    "    x = 'true_w',\n",
    "    y = 'w',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0584292",
   "metadata": {},
   "source": [
    "# T = MAC 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69096c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_df_list = []\n",
    "for w in [0, .05, .25, .5, .75, .95, 1]:\n",
    "    files = os.listdir(f'/n/groups/price/jordan/h2xancestry/data/simulations/alpha_mix_2/w_{w}_alpha_.38_h2_.5_thresholded_MAC1')\n",
    "    grouped_trait_files = [f for f in files if f.endswith('.alpha_mix.skip_jackknife.txt') and f.startswith('seeds')]\n",
    "    for f in grouped_trait_files:\n",
    "        df = pd.read_csv(\n",
    "            f'/n/groups/price/jordan/h2xancestry/data/simulations/alpha_mix_2/w_{w}_alpha_.38_h2_.5_thresholded_MAC1/{f}', \n",
    "            sep = '\\t'\n",
    "        ).assign(\n",
    "            true_w = w,\n",
    "            seed_start = f.split('_')[1],\n",
    "            seed_end = f.split('_')[2].split('.')[0]\n",
    "        ).assign(inference = 'Baseline-LD (v2.2) + 2-D MAF bins')\n",
    "        w_df_list.append(df)\n",
    "w_df = pd.concat(w_df_list)\n",
    "w_df.to_csv('/n/groups/price/jordan/h2xancestry/data/simulations/alpha_mix_2/simulation_summaries/alpha_.38_h2_.5_thresholded_MAC1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5d5d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(\n",
    "    w_df,\n",
    "    x = 'true_w',\n",
    "    y = 'w',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41df27c",
   "metadata": {},
   "source": [
    "# main sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0423459",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_df_list = []\n",
    "for w in [0, .05, .25, .5, .75, .95, 1]:\n",
    "    files = os.listdir(f'/n/groups/price/jordan/h2xancestry/data/simulations/alpha_mix_2/w_{w}_alpha_.38_h2_.5_thresholded_.005')\n",
    "    grouped_trait_files = [f for f in files if f.endswith('.alpha_mix.skip_jackknife.txt') and f.startswith('seeds')]\n",
    "    for f in grouped_trait_files:\n",
    "        df = pd.read_csv(\n",
    "            f'/n/groups/price/jordan/h2xancestry/data/simulations/alpha_mix_2/w_{w}_alpha_.38_h2_.5_thresholded_.005/{f}', \n",
    "            sep = '\\t'\n",
    "        ).assign(\n",
    "            true_w = w,\n",
    "            seed_start = f.split('_')[1],\n",
    "            seed_end = f.split('_')[2].split('.')[0]\n",
    "        ).assign(inference = 'Baseline-LD (v2.2) + 2-D MAF bins')\n",
    "        w_df_list.append(df)\n",
    "w_df = pd.concat(w_df_list)\n",
    "w_df.to_csv('/n/groups/price/jordan/h2xancestry/data/simulations/alpha_mix_2/simulation_summaries/alpha_.38_h2_.5_thresholded_.005.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3b4d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(\n",
    "    w_df,\n",
    "    x = 'true_w',\n",
    "    y = 'w',\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
