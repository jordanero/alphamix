{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get afr unadmixed maf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chrom in tqdm.tqdm(range(1,23)):\n",
    "    ref = pd.read_csv(\n",
    "        f'/n/groups/price/ldsc/reference_files/1000G_EUR_Phase3/plink_files/1000G.EUR.QC.{chrom}.bim',\n",
    "        sep = '\\t',\n",
    "        names = ['CHR', 'SNP', 'CM', 'BP', 'A1', 'A2']\n",
    "    ).assign(\n",
    "        CHR = lambda df: df.CHR.astype(str)\n",
    "    )\n",
    "\n",
    "    af = pd.read_csv(\n",
    "        f'/n/groups/price/jordan/h2xancestry/data/af/afr_unadmixed/chr{chrom}_afr_unadmixed_with_rsid_lifted.tsv', \n",
    "        sep = '\\t',\n",
    "        header = None,\n",
    "        names = ['#CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT', 'SAMPLE']\n",
    "    ).assign(\n",
    "        MAF_afr = lambda df: df.SAMPLE,\n",
    "        A1 = lambda df: df.ALT,\n",
    "        A2 = lambda df: df.REF,\n",
    "        BP = lambda df: df.POS,\n",
    "        CHR = lambda df: df['#CHROM'].astype(str),\n",
    "        actual_MAF_afr = lambda df: np.minimum(df.MAF_afr, 1 - df.MAF_afr)\n",
    "    ).query(\n",
    "        'REF.str.len() == 1 & ALT.str.len() == 1'\n",
    "    )\n",
    "\n",
    "    aou_maf_maxed_by_rsid = af.copy()\n",
    "    aou_maf_maxed_by_rsid['ID'] = aou_maf_maxed_by_rsid.ID.str.split(',')\n",
    "    aou_maf_maxed_by_rsid = aou_maf_maxed_by_rsid.explode('ID')\n",
    "\n",
    "    aou_maf_maxed_by_rsid = aou_maf_maxed_by_rsid.assign(\n",
    "        SNP = lambda df: df.ID\n",
    "    ).sort_values(\n",
    "        'actual_MAF_afr',\n",
    "    ).groupby(\n",
    "        ['SNP', 'A1', 'A2']\n",
    "    ).last(\n",
    "    ).reset_index(\n",
    "    )[\n",
    "        ['SNP', 'MAF_afr', 'A1', 'A2']\n",
    "    ]\n",
    "\n",
    "    af_forward_rsid_maxed = aou_maf_maxed_by_rsid.rename(\n",
    "        columns = {'MAF_afr' : 'MAF_afr_forward_match_rsid'}\n",
    "    )\n",
    "\n",
    "    af_backward_rsid_maxed = aou_maf_maxed_by_rsid.assign(\n",
    "        MAF_afr = lambda df: 1 - df.MAF_afr\n",
    "    ).rename(\n",
    "        columns = {'MAF_afr' : 'MAF_afr_backward_match_rsid'}\n",
    "    )\n",
    "    old_A1 = af_backward_rsid_maxed.A1\n",
    "    old_A2 = af_backward_rsid_maxed.A2\n",
    "    af_backward_rsid_maxed['A1'] = old_A2\n",
    "    af_backward_rsid_maxed['A2'] = old_A1\n",
    "    \n",
    "    aou_maf_maxed_by_coord = af.sort_values(\n",
    "        ['POS', 'actual_MAF_afr']\n",
    "    ).groupby(\n",
    "        ['POS', 'REF', 'ALT']\n",
    "    ).last(\n",
    "    ).reset_index(\n",
    "    )\n",
    "    assert all(aou_maf_maxed_by_coord[['A1', 'A2', 'BP']].value_counts() == 1)\n",
    "\n",
    "    af_forward = aou_maf_maxed_by_coord.assign(\n",
    "        MAF_afr_forward_match = lambda df: df.MAF_afr\n",
    "    )[\n",
    "        ['A1', 'A2', 'BP', 'MAF_afr_forward_match']\n",
    "    ]\n",
    "    \n",
    "    af_swapped = aou_maf_maxed_by_coord.assign(\n",
    "        MAF_afr_backward_match = lambda df: 1 - df.MAF_afr\n",
    "    )[\n",
    "        ['A1', 'A2', 'BP', 'MAF_afr_backward_match']\n",
    "    ]\n",
    "    old_A1 = af_swapped.A1\n",
    "    old_A2 = af_swapped.A2\n",
    "    af_swapped['A1'] = old_A2\n",
    "    af_swapped['A2'] = old_A1\n",
    "\n",
    "    yri_bim = pd.read_csv(\n",
    "        f'/n/groups/price/jordan/h2xancestry/data/plink/1000G_YRI/1000G.YRI.{chrom}.bim',\n",
    "        sep = '\\\\s+',\n",
    "        header = None,\n",
    "        names = ['CHR', 'SNP', 'CM', 'BP', 'A1', 'A2']\n",
    "    )\n",
    "    yri_af = pd.read_csv(\n",
    "        f'/n/groups/price/jordan/h2xancestry/data/plink/1000G_YRI/1000G.YRI.{chrom}.frq',\n",
    "        sep = '\\\\s+'\n",
    "    )\n",
    "    yri_af_forward = yri_bim.assign(MAF_YRI_forward = yri_af.MAF)\n",
    "    yri_af_swapped = yri_bim.assign(MAF_YRI_backward = 1 - yri_af.MAF)\n",
    "    old_A1 = yri_af_swapped.A1\n",
    "    old_A2 = yri_af_swapped.A2\n",
    "    yri_af_swapped['A1'] = old_A2\n",
    "    yri_af_swapped['A2'] = old_A1\n",
    "    yri_af_forward.head()\n",
    "\n",
    "    ref_rsid_and_coord_matched = ref.merge(\n",
    "        af_forward,\n",
    "        how = 'left',\n",
    "        sort = False\n",
    "    ).merge(\n",
    "        af_swapped,\n",
    "        how = 'left',\n",
    "        sort = False\n",
    "    ).merge(\n",
    "        af_forward_rsid_maxed,\n",
    "        how = 'left',\n",
    "        sort = False\n",
    "    ).merge(\n",
    "        af_backward_rsid_maxed,\n",
    "        how = 'left',\n",
    "        sort = False\n",
    "    ).merge(\n",
    "        yri_af_forward[['SNP', 'A1', 'A2', 'BP', 'MAF_YRI_forward']],\n",
    "        how = 'left'\n",
    "    ).merge(\n",
    "        yri_af_swapped[['SNP', 'A1', 'A2', 'BP', 'MAF_YRI_backward']],\n",
    "        how = 'left'\n",
    "    ).assign(\n",
    "       MAF_afr_coord = lambda df: [b if np.isnan(f) else f for f, b in zip(df.MAF_afr_forward_match, df.MAF_afr_backward_match)],\n",
    "       MAF_afr_rsid = lambda df: [b if np.isnan(f) else f for f, b in zip(df.MAF_afr_forward_match_rsid, df.MAF_afr_backward_match_rsid)],\n",
    "       MAF_YRI = lambda df: [b if np.isnan(f) else f for f, b in zip(df.MAF_YRI_forward, df.MAF_YRI_backward)],\n",
    "       MAF_afr_aou = lambda df: [r if np.isnan(c) else c for c, r in zip(df.MAF_afr_coord, df.MAF_afr_rsid)],\n",
    "       MAF_afr = lambda df: [y if np.isnan(a) else a for a, y in zip(df.MAF_afr_aou, df.MAF_YRI)]\n",
    "    )\n",
    "\n",
    "    ref_rsid_and_coord_matched[\n",
    "        ['CHR', 'SNP', 'BP', 'A1', 'A2','MAF_afr', 'MAF_afr_aou', 'MAF_YRI']\n",
    "    ].to_csv(\n",
    "        f'/n/groups/price/jordan/h2xancestry/data/af/1000G_EUR_Phase3/1000G.EUR.QC.{chrom}.MAF_afr_v2.txt',\n",
    "        sep = '\\t',\n",
    "        index = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAF grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maf_df_list = []\n",
    "for chrom in tqdm.tqdm(range(1,23)):\n",
    "    afr_maf_chrom = pd.read_csv(\n",
    "        f'/n/groups/price/jordan/h2xancestry/data/af/1000G_EUR_Phase3/1000G.EUR.QC.{chrom}.MAF_afr_v2.txt',\n",
    "        sep = '\\t'\n",
    "    )\n",
    "    eur_maf_chrom = pd.read_csv(\n",
    "        f'/n/groups/price/ldsc/reference_files/1000G_EUR_Phase3/plink_files/1000G.EUR.QC.{chrom}.frq',\n",
    "        sep = '\\\\s+'\n",
    "    ).rename(\n",
    "        columns = {'MAF' : 'MAF_eur'}\n",
    "    ).assign(\n",
    "        MAF_afr = afr_maf_chrom.MAF_afr\n",
    "    ).assign(\n",
    "        MAF_afr = lambda df: np.minimum(df.MAF_afr, 1 - df.MAF_afr)\n",
    "    ).assign(\n",
    "        MAF_eur = lambda df: np.minimum(df.MAF_eur, 1 - df.MAF_eur)\n",
    "    )\n",
    "\n",
    "    maf_df_list.append(eur_maf_chrom)\n",
    "maf_df = pd.concat(\n",
    "    maf_df_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eur_common_maf_bins = np.quantile(maf_df.query('MAF_eur >= .05').MAF_eur, q = np.linspace(0, 1, 11))\n",
    "eur_common_maf_bins[0] = 0.05\n",
    "afr_maf_bins = np.concatenate([np.array([0, .005]), eur_common_maf_bins])\n",
    "maf_binned = maf_df.query(\n",
    "    'MAF_eur >= 0.05'\n",
    ").assign(\n",
    "    eur_maf_bin = lambda df: pd.cut(df.MAF_eur, bins = eur_common_maf_bins, precision = 4, include_lowest = True).astype(str).str.replace(' ', ''),\n",
    "    afr_maf_bin = lambda df: pd.cut(df.MAF_afr, bins = afr_maf_bins, precision = 4, include_lowest = True).astype(str).str.replace(' ', '')\n",
    ").assign(\n",
    "    combined_bin = lambda df: [f'eur_maf_{e}_afr_maf_{a}' for (e, a) in zip(df.eur_maf_bin, df.afr_maf_bin)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_maf_df = maf_df.query('MAF_eur >= 0.05')\n",
    "dummy_matrix = pd.get_dummies(maf_binned[['combined_bin']], dtype = int)\n",
    "dummy_labels = dummy_matrix.columns\n",
    "dummy_matrix = dummy_matrix.assign(\n",
    "    CHR = common_maf_df.CHR,\n",
    "    SNP = common_maf_df.SNP,\n",
    "    A1 = common_maf_df.A1,\n",
    "    A2 = common_maf_df.A2\n",
    ")\n",
    "\n",
    "for chrom in tqdm.tqdm(range(1,23)):\n",
    "    ref_annotated = pd.read_csv(\n",
    "        f'/n/groups/price/ldsc/reference_files/1000G_EUR_Phase3/plink_files/1000G.EUR.QC.{chrom}.bim',\n",
    "        sep = '\\t',\n",
    "        header=None, \n",
    "        names = ['CHR', 'SNP', 'CM', 'BP', 'A1', 'A2']\n",
    "    ).merge(\n",
    "        dummy_matrix.query('CHR == @chrom'),\n",
    "        how = 'left'\n",
    "    ).fillna(\n",
    "        {k : 0 for k in dummy_labels}\n",
    "    )\n",
    "    ref_annotated[\n",
    "        ['CHR', 'BP', 'SNP', 'CM'] + dummy_labels.tolist()\n",
    "    ].to_csv(\n",
    "        f'/n/groups/price/jordan/h2xancestry/data/ldscores/1000G_EUR_Phase3/maf_grid/maf_grid.{chrom}.annot.gz',\n",
    "        sep = '\\t',\n",
    "        index = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maf_binned.assign(\n",
    "    maf_afr_times_one_minus_maf_afr = lambda df: df.MAF_afr * (1 - df.MAF_afr)\n",
    ").groupby(\n",
    "    'afr_maf_bin'\n",
    ").apply(lambda df: pd.DataFrame({\n",
    "    'MAF_afr' : [np.mean(df.MAF_afr)], 'maf_afr_times_one_minus_maf_afr' : np.mean(df.maf_afr_times_one_minus_maf_afr), 'n' : df.shape[0]\n",
    "})).reset_index(\n",
    ").drop(\n",
    "    columns = ['level_1']\n",
    "#).to_csv(\n",
    "#    '/n/groups/price/jordan/h2xancestry/data/ldscores/1000G_EUR_Phase3/maf_grid_afr_maf_bins/maf_bin_variance_means.csv',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_maf_df = maf_df.query('MAF_eur >= 0.05')\n",
    "dummy_matrix = pd.get_dummies(maf_binned[['afr_maf_bin']], dtype = int)\n",
    "dummy_labels = dummy_matrix.columns\n",
    "dummy_matrix = dummy_matrix.assign(\n",
    "    CHR = common_maf_df.CHR,\n",
    "    SNP = common_maf_df.SNP,\n",
    "    A1 = common_maf_df.A1,\n",
    "    A2 = common_maf_df.A2\n",
    ")\n",
    "\n",
    "for chrom in tqdm.tqdm(range(1,23)):\n",
    "    ref_annotated = pd.read_csv(\n",
    "        f'/n/groups/price/ldsc/reference_files/1000G_EUR_Phase3/plink_files/1000G.EUR.QC.{chrom}.bim',\n",
    "        sep = '\\t',\n",
    "        header=None, \n",
    "        names = ['CHR', 'SNP', 'CM', 'BP', 'A1', 'A2']\n",
    "    ).merge(\n",
    "        dummy_matrix.query('CHR == @chrom'),\n",
    "        how = 'left'\n",
    "    ).fillna(\n",
    "        {k : 0 for k in dummy_labels}\n",
    "    )\n",
    "    ref_annotated[\n",
    "        ['CHR', 'BP', 'SNP', 'CM'] + dummy_labels.tolist()\n",
    "    ].to_csv(\n",
    "        f'/n/groups/price/jordan/h2xancestry/data/ldscores/1000G_EUR_Phase3/maf_grid_afr_maf_bins/maf_grid_afr_maf_bins.{chrom}.annot.gz',\n",
    "        sep = '\\t',\n",
    "        index = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_maf_df = maf_df.query('MAF_eur >= 0.05')\n",
    "dummy_matrix = pd.get_dummies(maf_binned[['combined_bin']], dtype = int)\n",
    "dummy_labels = dummy_matrix.columns\n",
    "dummy_matrix = dummy_matrix.assign(\n",
    "    CHR = common_maf_df.CHR,\n",
    "    SNP = common_maf_df.SNP,\n",
    "    A1 = common_maf_df.A1,\n",
    "    A2 = common_maf_df.A2\n",
    ")\n",
    "\n",
    "for chrom in tqdm.tqdm(range(1,23)):\n",
    "    ref_annotated = pd.read_csv(\n",
    "        f'/n/groups/price/ldsc/reference_files/1000G_EUR_Phase3/plink_files/1000G.EUR.QC.{chrom}.bim',\n",
    "        sep = '\\t',\n",
    "        header=None, \n",
    "        names = ['CHR', 'SNP', 'CM', 'BP', 'A1', 'A2']\n",
    "    ).merge(\n",
    "        dummy_matrix.query('CHR == @chrom'),\n",
    "        how = 'left'\n",
    "    ).fillna(\n",
    "        {k : 0 for k in dummy_labels}\n",
    "    )\n",
    "    ref_annotated[\n",
    "        ['CHR', 'BP', 'SNP', 'CM'] + dummy_labels.tolist()\n",
    "    ].to_csv(\n",
    "        f'/n/groups/price/jordan/h2xancestry/data/ldscores/1000G_EUR_Phase3/maf_grid/maf_grid.{chrom}.annot.gz',\n",
    "        sep = '\\t',\n",
    "        index = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coarse MAF grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maf_df_list = []\n",
    "for chrom in tqdm.tqdm(range(1,23)):\n",
    "    afr_maf_chrom = pd.read_csv(\n",
    "        f'/n/groups/price/jordan/h2xancestry/data/af/1000G_EUR_Phase3/1000G.EUR.QC.{chrom}.MAF_afr_v2.txt',\n",
    "        sep = '\\t'\n",
    "    )\n",
    "    eur_maf_chrom = pd.read_csv(\n",
    "        f'/n/groups/price/ldsc/reference_files/1000G_EUR_Phase3/plink_files/1000G.EUR.QC.{chrom}.frq',\n",
    "        sep = '\\\\s+'\n",
    "    ).rename(\n",
    "        columns = {'MAF' : 'MAF_eur'}\n",
    "    ).assign(\n",
    "        MAF_afr = afr_maf_chrom.MAF_afr\n",
    "    ).assign(\n",
    "        MAF_afr = lambda df: np.minimum(df.MAF_afr, 1 - df.MAF_afr)\n",
    "    ).assign(\n",
    "        MAF_eur = lambda df: np.minimum(df.MAF_eur, 1 - df.MAF_eur)\n",
    "    )\n",
    "\n",
    "    maf_df_list.append(eur_maf_chrom)\n",
    "maf_df = pd.concat(\n",
    "    maf_df_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eur_common_maf_bins = np.quantile(maf_df.query('MAF_eur >= .05').MAF_eur, q = np.linspace(0, 1, 6))\n",
    "eur_common_maf_bins[0] = 0.05\n",
    "afr_maf_bins = np.concatenate([np.array([0, .005]), eur_common_maf_bins])\n",
    "maf_binned = maf_df.query(\n",
    "    'MAF_eur >= 0.05'\n",
    ").assign(\n",
    "    eur_maf_bin = lambda df: pd.cut(df.MAF_eur, bins = eur_common_maf_bins, precision = 4, include_lowest = True).astype(str).str.replace(' ', ''),\n",
    "    afr_maf_bin = lambda df: pd.cut(df.MAF_afr, bins = afr_maf_bins, precision = 4, include_lowest = True).astype(str).str.replace(' ', '')\n",
    ").assign(\n",
    "    combined_bin = lambda df: [f'eur_maf_{e}_afr_maf_{a}' for (e, a) in zip(df.eur_maf_bin, df.afr_maf_bin)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maf_binned.groupby(\n",
    "    ['eur_maf_bin', 'afr_maf_bin', 'combined_bin']\n",
    ")[\n",
    "    ['MAF_eur', 'MAF_afr']\n",
    "].mean(\n",
    ").reset_index(\n",
    ").to_csv(\n",
    "    '/n/groups/price/jordan/h2xancestry/data/ldscores/1000G_EUR_Phase3/coarse_maf_grid/maf_bin_means.csv',\n",
    "    index = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_maf_df = maf_df.query('MAF_eur >= 0.05')\n",
    "dummy_matrix = pd.get_dummies(maf_binned[['combined_bin']], dtype = int)\n",
    "dummy_labels = dummy_matrix.columns\n",
    "dummy_matrix = dummy_matrix.assign(\n",
    "    CHR = common_maf_df.CHR,\n",
    "    SNP = common_maf_df.SNP,\n",
    "    A1 = common_maf_df.A1,\n",
    "    A2 = common_maf_df.A2\n",
    ")\n",
    "\n",
    "for chrom in tqdm.tqdm(range(1,23)):\n",
    "    ref_annotated = pd.read_csv(\n",
    "        f'/n/groups/price/ldsc/reference_files/1000G_EUR_Phase3/plink_files/1000G.EUR.QC.{chrom}.bim',\n",
    "        sep = '\\t',\n",
    "        header=None, \n",
    "        names = ['CHR', 'SNP', 'CM', 'BP', 'A1', 'A2']\n",
    "    ).merge(\n",
    "        dummy_matrix.query('CHR == @chrom'),\n",
    "        how = 'left'\n",
    "    ).fillna(\n",
    "        {k : 0 for k in dummy_labels}\n",
    "    )\n",
    "    ref_annotated[\n",
    "        ['CHR', 'BP', 'SNP', 'CM'] + dummy_labels.tolist()\n",
    "    ].to_csv(\n",
    "        f'/n/groups/price/jordan/h2xancestry/data/ldscores/1000G_EUR_Phase3/coarse_maf_grid/coarse_maf_grid.{chrom}.annot.gz',\n",
    "        sep = '\\t',\n",
    "        index = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_maf_df = maf_df.query('MAF_eur >= 0.05')\n",
    "dummy_matrix = pd.get_dummies(maf_binned[['afr_maf_bin']], dtype = int)\n",
    "dummy_labels = dummy_matrix.columns\n",
    "dummy_matrix = dummy_matrix.assign(\n",
    "    CHR = common_maf_df.CHR,\n",
    "    SNP = common_maf_df.SNP,\n",
    "    A1 = common_maf_df.A1,\n",
    "    A2 = common_maf_df.A2\n",
    ")\n",
    "\n",
    "for chrom in tqdm.tqdm(range(1,23)):\n",
    "    ref_annotated = pd.read_csv(\n",
    "        f'/n/groups/price/ldsc/reference_files/1000G_EUR_Phase3/plink_files/1000G.EUR.QC.{chrom}.bim',\n",
    "        sep = '\\t',\n",
    "        header=None, \n",
    "        names = ['CHR', 'SNP', 'CM', 'BP', 'A1', 'A2']\n",
    "    ).merge(\n",
    "        dummy_matrix.query('CHR == @chrom'),\n",
    "        how = 'left'\n",
    "    ).fillna(\n",
    "        {k : 0 for k in dummy_labels}\n",
    "    )\n",
    "    ref_annotated[\n",
    "        ['CHR', 'BP', 'SNP', 'CM'] + dummy_labels.tolist()\n",
    "    ].to_csv(\n",
    "        f'/n/groups/price/jordan/h2xancestry/data/ldscores/1000G_EUR_Phase3/coarse_maf_grid_afr_maf_bins/coarse_maf_grid_afr_maf_bins.{chrom}.annot.gz',\n",
    "        sep = '\\t',\n",
    "        index = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maf_binned.assign(\n",
    "    maf_afr_times_one_minus_maf_afr = lambda df: df.MAF_afr * (1 - df.MAF_afr)\n",
    ").groupby(\n",
    "    'afr_maf_bin'\n",
    ")[\n",
    "    'maf_afr_times_one_minus_maf_afr'\n",
    "].mean(\n",
    ").reset_index(\n",
    ").to_csv(\n",
    "    '/n/groups/price/jordan/h2xancestry/data/ldscores/1000G_EUR_Phase3/coarse_maf_grid_afr_maf_bins/maf_bin_variance_means.csv',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eur MAF bins stratified by AFR maf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "maf_df_list = []\n",
    "for chrom in tqdm.tqdm(range(1,23)):\n",
    "    afr_maf_chrom = pd.read_csv(\n",
    "        f'/n/groups/price/jordan/h2xancestry/data/af/1000G_EUR_Phase3/1000G.EUR.QC.{chrom}.MAF_afr_v2.txt',\n",
    "        sep = '\\t'\n",
    "    )\n",
    "    eur_maf_chrom = pd.read_csv(\n",
    "        f'/n/groups/price/ldsc/reference_files/1000G_EUR_Phase3/plink_files/1000G.EUR.QC.{chrom}.frq',\n",
    "        sep = '\\\\s+'\n",
    "    ).rename(\n",
    "        columns = {'MAF' : 'MAF_eur'}\n",
    "    ).assign(\n",
    "        MAF_afr = afr_maf_chrom.MAF_afr\n",
    "    ).assign(\n",
    "        MAF_afr = lambda df: np.minimum(df.MAF_afr, 1 - df.MAF_afr)\n",
    "    ).assign(\n",
    "        MAF_eur = lambda df: np.minimum(df.MAF_eur, 1 - df.MAF_eur)\n",
    "    )\n",
    "\n",
    "    maf_df_list.append(eur_maf_chrom)\n",
    "maf_df = pd.concat(\n",
    "    maf_df_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eur_common_maf_deciles_in_afr_c = np.quantile(maf_df.query('MAF_eur >= .05').query('MAF_afr >= .05').MAF_eur, q = np.linspace(0, 1, 11))\n",
    "eur_common_maf_deciles_in_afr_lf = np.quantile(maf_df.query('MAF_eur >= .05').query('.005 <= MAF_afr < .05').MAF_eur, q = np.linspace(0, 1, 11))\n",
    "eur_common_maf_deciles = np.quantile(maf_df.query('MAF_eur >= .05').MAF_eur, q = np.linspace(0, 1, 11))\n",
    "eur_common_maf_deciles_in_afr_rare = np.quantile(maf_df.query('MAF_eur >= .05').query('MAF_afr <= .005').MAF_eur, q = np.linspace(0, 1, 11))\n",
    "afr_common_maf_deciles_in_eur_c = np.quantile(maf_df.query('MAF_eur >= .05').query('MAF_afr >= .05').MAF_afr, q = np.linspace(0, 1, 11))\n",
    "\n",
    "eur_common_maf_deciles_in_afr_c[0] = .05\n",
    "eur_common_maf_deciles_in_afr_lf[0] = .05\n",
    "eur_common_maf_deciles[0] = .05\n",
    "eur_common_maf_deciles_in_afr_rare[0] = .05\n",
    "afr_common_maf_deciles_in_eur_c[0] = .05\n",
    "\n",
    "eur_common_maf_quintiles_in_afr_c = np.quantile(maf_df.query('MAF_eur >= .05').query('MAF_afr >= .05').MAF_eur, q = np.linspace(0, 1, 6))\n",
    "eur_common_maf_quintiles_in_afr_lf = np.quantile(maf_df.query('MAF_eur >= .05').query('.005 <= MAF_afr < .05').MAF_eur, q = np.linspace(0, 1, 6))\n",
    "eur_common_maf_quintiles = np.quantile(maf_df.query('MAF_eur >= .05').MAF_eur, q = np.linspace(0, 1, 6))\n",
    "eur_common_maf_quintiles_in_afr_rare = np.quantile(maf_df.query('MAF_eur >= .05').query('MAF_afr <= .005').MAF_eur, q = np.linspace(0, 1, 6))\n",
    "afr_common_maf_quintiles_in_eur_c = np.quantile(maf_df.query('MAF_eur >= .05').query('MAF_afr >= .05').MAF_afr, q = np.linspace(0, 1, 6))\n",
    "\n",
    "eur_common_maf_quintiles_in_afr_c[0] = .05\n",
    "eur_common_maf_quintiles_in_afr_lf[0] = .05\n",
    "eur_common_maf_quintiles[0] = .05\n",
    "eur_common_maf_quintiles_in_afr_rare[0] = .05\n",
    "afr_common_maf_quintiles_in_eur_c[0] = .05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eur_maf_binned_in_afr_c = maf_df.query(\n",
    "    'MAF_afr >= .05'\n",
    ").query(\n",
    "    'MAF_eur >= .05'\n",
    ").assign(\n",
    "    eur_maf_decile_in_afr_c = lambda df: pd.cut(df.MAF_eur, bins = eur_common_maf_deciles_in_afr_c, precision = 4, include_lowest = True).astype(str),\n",
    "    eur_maf_quintile_in_afr_c = lambda df: pd.cut(df.MAF_eur, bins = eur_common_maf_quintiles_in_afr_c, precision = 4, include_lowest = True).astype(str),\n",
    ")\n",
    "eur_maf_binned_in_afr_lf = maf_df.query(\n",
    "    '.005 <= MAF_afr < .05'\n",
    ").query(\n",
    "    'MAF_eur >= .05'\n",
    ").assign(\n",
    "    eur_maf_decile_in_afr_lf = lambda df: pd.cut(df.MAF_eur, bins = eur_common_maf_deciles_in_afr_lf, precision = 4, include_lowest = True).astype(str),\n",
    "    eur_maf_quintile_in_afr_lf = lambda df: pd.cut(df.MAF_eur, bins = eur_common_maf_quintiles_in_afr_lf, precision = 4, include_lowest = True).astype(str),\n",
    ")\n",
    "eur_maf_binned_in_afr_rare = maf_df.query(\n",
    "    'MAF_afr < .005'\n",
    ").query(\n",
    "    'MAF_eur >= .05'\n",
    ").assign(\n",
    "    eur_maf_decile_in_afr_rare = lambda df: pd.cut(df.MAF_eur, bins = eur_common_maf_deciles_in_afr_rare, precision = 4, include_lowest = True).astype(str),\n",
    "    eur_maf_quintile_in_afr_rare = lambda df: pd.cut(df.MAF_eur, bins = eur_common_maf_quintiles_in_afr_rare, precision = 4, include_lowest = True).astype(str),\n",
    ")\n",
    "eur_maf_binned = maf_df.query(\n",
    "    'MAF_eur >= .05'\n",
    ").assign(\n",
    "    eur_maf_decile = lambda df: pd.cut(df.MAF_eur, bins = eur_common_maf_deciles, precision = 4, include_lowest = True).astype(str),\n",
    "    eur_maf_quintile = lambda df: pd.cut(df.MAF_eur, bins = eur_common_maf_quintiles, precision = 4, include_lowest = True).astype(str),\n",
    ")\n",
    "afr_maf_binned_in_eur_c = maf_df.query(\n",
    "    'MAF_eur >= .05'\n",
    ").query(\n",
    "    'MAF_afr >= .05'\n",
    ").assign(\n",
    "    afr_maf_decile_in_eur_c = lambda df: pd.cut(df.MAF_afr, bins = afr_common_maf_deciles_in_eur_c, precision = 4, include_lowest = True).astype(str),\n",
    "    afr_maf_quintile_in_eur_c = lambda df: pd.cut(df.MAF_afr, bins = afr_common_maf_quintiles_in_eur_c, precision = 4, include_lowest = True).astype(str),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "annot_list = [eur_maf_binned_in_afr_c, eur_maf_binned_in_afr_lf, eur_maf_binned_in_afr_rare, eur_maf_binned, afr_maf_binned_in_eur_c]\n",
    "annot_list_formatted = [df.drop(columns = ['MAF_eur', 'NCHROBS', 'MAF_afr']) for df in annot_list]\n",
    "combined_annot = reduce(lambda df1, df2: df1.merge(df2, how = 'outer'), tqdm.tqdm(annot_list_formatted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_matrix = pd.get_dummies(\n",
    "    combined_annot[sum([[f'eur_maf_{b}_in_afr_c', f'eur_maf_{b}_in_afr_lf', f'eur_maf_{b}_in_afr_rare', f'eur_maf_{b}', f'afr_maf_{b}_in_eur_c'] for b in ['decile', 'quintile']], [])], \n",
    "    dtype = int \n",
    ")\n",
    "dummy_labels = dummy_matrix.columns\n",
    "dummy_matrix = dummy_matrix.assign(\n",
    "    CHR = combined_annot.CHR,\n",
    "    SNP = combined_annot.SNP,\n",
    "    A1 = combined_annot.A1,\n",
    "    A2 = combined_annot.A2\n",
    ")\n",
    "\n",
    "for chrom in tqdm.tqdm(range(1,23)):\n",
    "    ref_annotated = pd.read_csv(\n",
    "        f'/n/groups/price/ldsc/reference_files/1000G_EUR_Phase3/plink_files/1000G.EUR.QC.{chrom}.bim',\n",
    "        sep = '\\t',\n",
    "        header=None, \n",
    "        names = ['CHR', 'SNP', 'CM', 'BP', 'A1', 'A2']\n",
    "    ).merge(\n",
    "        dummy_matrix.query('CHR == @chrom'),\n",
    "        how = 'left'\n",
    "    ).fillna(\n",
    "        {k : 0 for k in dummy_labels}\n",
    "    )\n",
    "    ref_annotated[\n",
    "        ['CHR', 'BP', 'SNP', 'CM'] + dummy_labels.tolist()\n",
    "    ].to_csv(\n",
    "        f'/n/groups/price/jordan/h2xancestry/data/ldscores/1000G_EUR_Phase3/maf_bins_stratified_by_afr_maf_corrected/maf_bins_stratified_by_afr_maf_corrected.{chrom}.annot.gz',\n",
    "        sep = '\\t',\n",
    "        index = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eur_maf_deciles_in_afr_c_means = eur_maf_binned_in_afr_c.groupby('eur_maf_decile_in_afr_c')[['MAF_eur']].mean().reset_index().assign(\n",
    "    bin = lambda df: 'eur_maf_decile_in_afr_c_' + df.eur_maf_decile_in_afr_c,\n",
    "    MAF = lambda df: df.MAF_eur\n",
    ")\n",
    "eur_maf_deciles_in_afr_lf_means = eur_maf_binned_in_afr_lf.groupby('eur_maf_decile_in_afr_lf')[['MAF_eur']].mean().reset_index().assign(\n",
    "    bin = lambda df: 'eur_maf_decile_in_afr_lf_' + df.eur_maf_decile_in_afr_lf,\n",
    "    MAF = lambda df: df.MAF_eur\n",
    ")\n",
    "eur_maf_deciles_in_afr_rare_means = eur_maf_binned_in_afr_rare.groupby('eur_maf_decile_in_afr_rare')[['MAF_eur']].mean().reset_index().assign(\n",
    "    bin = lambda df: 'eur_maf_decile_in_afr_rare_' + df.eur_maf_decile_in_afr_rare,\n",
    "    MAF = lambda df: df.MAF_eur\n",
    ")\n",
    "eur_maf_deciles_means = eur_maf_binned.groupby('eur_maf_decile')[['MAF_eur']].mean().reset_index().assign(\n",
    "    bin = lambda df: 'eur_maf_decile_' + df.eur_maf_decile,\n",
    "    MAF = lambda df: df.MAF_eur\n",
    ")\n",
    "afr_maf_deciles_in_eur_c_means = afr_maf_binned_in_eur_c.groupby('afr_maf_decile_in_eur_c')[['MAF_afr']].mean().reset_index().assign(\n",
    "    bin = lambda df: 'afr_maf_decile_in_eur_c_' + df.afr_maf_decile_in_eur_c,\n",
    "    MAF = lambda df: df.MAF_afr\n",
    ")\n",
    "eur_maf_quintiles_in_afr_c_means = eur_maf_binned_in_afr_c.groupby('eur_maf_quintile_in_afr_c')[['MAF_eur']].mean().reset_index().assign(\n",
    "    bin = lambda df: 'eur_maf_quintile_in_afr_c_' + df.eur_maf_quintile_in_afr_c,\n",
    "    MAF = lambda df: df.MAF_eur\n",
    ")\n",
    "eur_maf_quintiles_in_afr_lf_means = eur_maf_binned_in_afr_lf.groupby('eur_maf_quintile_in_afr_lf')[['MAF_eur']].mean().reset_index().assign(\n",
    "    bin = lambda df: 'eur_maf_quintile_in_afr_lf_' + df.eur_maf_quintile_in_afr_lf,\n",
    "    MAF = lambda df: df.MAF_eur\n",
    ")\n",
    "eur_maf_quintiles_in_afr_rare_means = eur_maf_binned_in_afr_rare.groupby('eur_maf_quintile_in_afr_rare')[['MAF_eur']].mean().reset_index().assign(\n",
    "    bin = lambda df: 'eur_maf_quintile_in_afr_rare_' + df.eur_maf_quintile_in_afr_rare,\n",
    "    MAF = lambda df: df.MAF_eur\n",
    ")\n",
    "eur_maf_quintiles_means = eur_maf_binned.groupby('eur_maf_quintile')[['MAF_eur']].mean().reset_index().assign(\n",
    "    bin = lambda df: 'eur_maf_quintile_' + df.eur_maf_quintile,\n",
    "    MAF = lambda df: df.MAF_eur\n",
    ")\n",
    "afr_maf_quintiles_in_eur_c_means = afr_maf_binned_in_eur_c.groupby('afr_maf_quintile_in_eur_c')[['MAF_afr']].mean().reset_index().assign(\n",
    "    bin = lambda df: 'afr_maf_quintile_in_eur_c_' + df.afr_maf_quintile_in_eur_c,\n",
    "    MAF = lambda df: df.MAF_afr\n",
    ")\n",
    "combined_maf_bin_means = pd.concat([df[['bin', 'MAF']] for df in [\n",
    "    eur_maf_deciles_in_afr_c_means, \n",
    "    eur_maf_deciles_in_afr_lf_means, \n",
    "    eur_maf_deciles_in_afr_rare_means, \n",
    "    eur_maf_deciles_means, \n",
    "    afr_maf_deciles_in_eur_c_means, \n",
    "    eur_maf_quintiles_in_afr_c_means, \n",
    "    eur_maf_quintiles_in_afr_lf_means, \n",
    "    eur_maf_quintiles_in_afr_rare_means, \n",
    "    eur_maf_quintiles_means, \n",
    "    afr_maf_quintiles_in_eur_c_means]])\n",
    "combined_maf_bin_means.to_csv('/n/groups/price/jordan/h2xancestry/data/ldscores/1000G_EUR_Phase3/maf_bins_stratified_by_afr_maf_corrected/maf_bin_means.csv', index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAF grid using YRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maf_df_list = []\n",
    "for chrom in tqdm.tqdm(range(1,23)):\n",
    "    afr_maf_chrom = pd.read_csv(\n",
    "        f'/n/groups/price/jordan/h2xancestry/data/af/1000G_EUR_Phase3/1000G.EUR.QC.{chrom}.MAF_afr_v2.txt',\n",
    "        sep = '\\t'\n",
    "    )\n",
    "    eur_maf_chrom = pd.read_csv(\n",
    "        f'/n/groups/price/ldsc/reference_files/1000G_EUR_Phase3/plink_files/1000G.EUR.QC.{chrom}.frq',\n",
    "        sep = '\\\\s+'\n",
    "    ).rename(\n",
    "        columns = {'MAF' : 'MAF_eur'}\n",
    "    ).assign(\n",
    "        MAF_afr = afr_maf_chrom.MAF_afr,\n",
    "        MAF_YRI = afr_maf_chrom.MAF_YRI,\n",
    "    ).assign(\n",
    "        MAF_afr = lambda df: np.minimum(df.MAF_afr, 1 - df.MAF_afr),\n",
    "        MAF_yri = lambda df: np.minimum(df.MAF_YRI, 1 - df.MAF_YRI),\n",
    "    ).assign(\n",
    "        MAF_eur = lambda df: np.minimum(df.MAF_eur, 1 - df.MAF_eur)\n",
    "    )\n",
    "\n",
    "    maf_df_list.append(eur_maf_chrom)\n",
    "maf_df = pd.concat(\n",
    "    maf_df_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eur_common_maf_bins = np.quantile(maf_df.query('MAF_eur >= .05').MAF_eur, q = np.linspace(0, 1, 11))\n",
    "eur_common_maf_bins[0] = 0.05\n",
    "yri_maf_bins = np.concatenate([np.array([0, .005]), eur_common_maf_bins])\n",
    "maf_binned = maf_df.query(\n",
    "    'MAF_eur >= 0.05'\n",
    ").assign(\n",
    "    eur_maf_bin = lambda df: pd.cut(df.MAF_eur, bins = eur_common_maf_bins, precision = 4, include_lowest = True).astype(str).str.replace(' ', ''),\n",
    "    yri_maf_bin = lambda df: pd.cut(df.MAF_yri, bins = yri_maf_bins, precision = 4, include_lowest = True).astype(str).str.replace(' ', '')\n",
    ").assign(\n",
    "    combined_bin = lambda df: [f'eur_maf_{e}_yri_maf_{a}' for (e, a) in zip(df.eur_maf_bin, df.yri_maf_bin)]\n",
    ")\n",
    "maf_binned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_maf_df = maf_df.query('MAF_eur >= 0.05')\n",
    "dummy_matrix = pd.get_dummies(maf_binned[['combined_bin']], dtype = int)\n",
    "dummy_labels = dummy_matrix.columns\n",
    "dummy_matrix = dummy_matrix.assign(\n",
    "    CHR = common_maf_df.CHR,\n",
    "    SNP = common_maf_df.SNP,\n",
    "    A1 = common_maf_df.A1,\n",
    "    A2 = common_maf_df.A2\n",
    ")\n",
    "\n",
    "for chrom in tqdm.tqdm(range(1,23)):\n",
    "    ref_annotated = pd.read_csv(\n",
    "        f'/n/groups/price/ldsc/reference_files/1000G_EUR_Phase3/plink_files/1000G.EUR.QC.{chrom}.bim',\n",
    "        sep = '\\t',\n",
    "        header=None, \n",
    "        names = ['CHR', 'SNP', 'CM', 'BP', 'A1', 'A2']\n",
    "    ).merge(\n",
    "        dummy_matrix.query('CHR == @chrom'),\n",
    "        how = 'left'\n",
    "    ).fillna(\n",
    "        {k : 0 for k in dummy_labels}\n",
    "    )\n",
    "    ref_annotated[\n",
    "        ['CHR', 'BP', 'SNP', 'CM'] + dummy_labels.tolist()\n",
    "    ].to_csv(\n",
    "        f'/n/groups/price/jordan/h2xancestry/data/ldscores/1000G_EUR_Phase3/maf_grid_yri/maf_grid_yri.{chrom}.annot.gz',\n",
    "        sep = '\\t',\n",
    "        index = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chr in tqdm.tqdm(range(1,23)):\n",
    "    maf = pd.read_csv('/n/groups/price/jordan/h2xancestry/data/af/1000G_EUR_Phase3/1000G.EUR.QC.22.MAF_afr_v2.txt', sep = '\\t')\n",
    "    maf.assign(\n",
    "        MAF_afr = lambda df: np.minimum(df.MAF_YRI, 1 - df.MAF_YRI)\n",
    "    ).to_csv(\n",
    "        f'/n/groups/price/jordan/h2xancestry/data/af/1000G_EUR_Phase3/1000G.EUR.QC.{chr}.MAF_yri_v2.txt',\n",
    "        sep = '\\t',\n",
    "        index = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_maf_df = maf_df.query('MAF_eur >= 0.05')\n",
    "dummy_matrix = pd.get_dummies(maf_binned[['yri_maf_bin']], dtype = int)\n",
    "dummy_labels = dummy_matrix.columns\n",
    "dummy_matrix = dummy_matrix.assign(\n",
    "    CHR = common_maf_df.CHR,\n",
    "    SNP = common_maf_df.SNP,\n",
    "    A1 = common_maf_df.A1,\n",
    "    A2 = common_maf_df.A2\n",
    ")\n",
    "\n",
    "for chrom in tqdm.tqdm(range(1,23)):\n",
    "    ref_annotated = pd.read_csv(\n",
    "        f'/n/groups/price/ldsc/reference_files/1000G_EUR_Phase3/plink_files/1000G.EUR.QC.{chrom}.bim',\n",
    "        sep = '\\t',\n",
    "        header=None, \n",
    "        names = ['CHR', 'SNP', 'CM', 'BP', 'A1', 'A2']\n",
    "    ).merge(\n",
    "        dummy_matrix.query('CHR == @chrom'),\n",
    "        how = 'left'\n",
    "    ).fillna(\n",
    "        {k : 0 for k in dummy_labels}\n",
    "    )\n",
    "    ref_annotated[\n",
    "        ['CHR', 'BP', 'SNP', 'CM'] + dummy_labels.tolist()\n",
    "    ].to_csv(\n",
    "        f'/n/groups/price/jordan/h2xancestry/data/ldscores/1000G_EUR_Phase3/maf_grid_yri_maf_bins/maf_grid_yri_maf_bins.{chrom}.annot.gz',\n",
    "        sep = '\\t',\n",
    "        index = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm.tqdm(range(1,23)):\n",
    "    annot = pd.read_csv(\n",
    "        f'/n/groups/price/jordan/h2xancestry/data/ldscores/1000G_EUR_Phase3/maf_grid_yri_maf_bins/maf_grid_yri_maf_bins.{i}.annot.gz',\n",
    "        sep = '\\t'\n",
    "    )\n",
    "    annot.columns = annot.columns[:4].tolist() + ['MAF_yribin_rare', 'MAF_yribin_lf'] + [f'MAF_yribin_{i}' for i in range(1,11)]\n",
    "    annot = annot.drop(\n",
    "        columns = ['MAF_yribin_10']\n",
    "    )\n",
    "    annot.to_csv(\n",
    "        f'/n/groups/price/jordan/h2xancestry/data/ldscores/1000G_EUR_Phase3/maf_grid_yri_maf_bins_ref_dropped/maf_grid_yri_maf_bins_ref_dropped.{i}.annot.gz',\n",
    "        sep = '\\t',\n",
    "        index = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BaselineLD2.2 without maf bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm.tqdm(range(10,23)):\n",
    "    annot = pd.read_csv(\n",
    "        f'/n/groups/price/ldsc/reference_files/1000G_EUR_Phase3/baselineLD_v2.2/baselineLD.{i}.annot.gz',\n",
    "        sep = '\\t'\n",
    "    )\n",
    "    non_maf_columns = [c for c in annot.columns if 'MAFbin' not in c]\n",
    "    annot_no_maf_bins = annot[non_maf_columns]\n",
    "    annot_no_maf_bins.to_csv(\n",
    "        f'/n/groups/price/jordan/h2xancestry/data/ldscores/1000G_EUR_Phase3/baselineLD2.2_no_maf_bins/baselineLD_no_maf_bins.{i}.annot.gz',\n",
    "        sep = '\\t',\n",
    "        index = False\n",
    "    )\n",
    "\n",
    "    ldscore_df = pd.read_csv(\n",
    "        f'/n/groups/price/ldsc/reference_files/1000G_EUR_Phase3/baselineLD_v2.2/baselineLD.{i}.l2.ldscore.gz',\n",
    "        sep = '\\t'\n",
    "    )\n",
    "    non_maf_columns = [c for c in ldscore_df.columns if 'MAFbin' not in c]\n",
    "    ldscore_df_no_maf_bins = ldscore_df[non_maf_columns]\n",
    "    ldscore_df_no_maf_bins.to_csv(\n",
    "        f'/n/groups/price/jordan/h2xancestry/data/ldscores/1000G_EUR_Phase3/baselineLD2.2_no_maf_bins/baselineLD_no_maf_bins.{i}.l2.ldscore.gz',\n",
    "        sep = '\\t',\n",
    "        index = False\n",
    "    )\n",
    "\n",
    "    M = pd.read_csv(\n",
    "        f'/n/groups/price/ldsc/reference_files/1000G_EUR_Phase3/baselineLD_v2.2/baselineLD.{i}.l2.M_5_50',\n",
    "        sep = '\\t',\n",
    "        names = [c for c in ldscore_df.columns if c not in ['CHR', 'BP', 'SNP', 'CM']]\n",
    "    )\n",
    "    non_maf_columns = [c for c in M.columns if 'MAFbin' not in c]\n",
    "    M_no_maf_bins = M[non_maf_columns]\n",
    "    M_no_maf_bins.to_csv(\n",
    "        f'/n/groups/price/jordan/h2xancestry/data/ldscores/1000G_EUR_Phase3/baselineLD2.2_no_maf_bins/baselineLD_no_maf_bins.{i}.l2.M_5_50',\n",
    "        sep = '\\t',\n",
    "        index = False,\n",
    "        header = False\n",
    "    )\n",
    "\n",
    "    M = pd.read_csv(\n",
    "        f'/n/groups/price/ldsc/reference_files/1000G_EUR_Phase3/baselineLD_v2.2/baselineLD.{i}.l2.M',\n",
    "        sep = '\\t',\n",
    "        names = [c for c in ldscore_df.columns if c not in ['CHR', 'BP', 'SNP', 'CM']]\n",
    "    )\n",
    "    non_maf_columns = [c for c in M.columns if 'MAFbin' not in c]\n",
    "    M_no_maf_bins = M[non_maf_columns]\n",
    "    M_no_maf_bins.to_csv(\n",
    "        f'/n/groups/price/jordan/h2xancestry/data/ldscores/1000G_EUR_Phase3/baselineLD2.2_no_maf_bins/baselineLD_no_maf_bins.{i}.l2.M',\n",
    "        sep = '\\t',\n",
    "        index = False,\n",
    "        header = False\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
